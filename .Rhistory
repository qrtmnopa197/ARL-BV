trials_frate_scale <- trials %>% filter(!is.na(feed_rate_z)) %>% mutate(feed_rate_z=scale(feed_rate_z),chosen_out=scale(chosen_out),unchosen_out=scale(unchosen_out))
stay_fit <- lmer(stay ~ feed_rate_z + chosen_out + unchosen_out + (feed_rate_z + chosen_out + unchosen_out | sub_index),trials_frate_scale)
summary(stay_fit)
anova(stay_fit)
library(lmerTest)
detach(lme4)
detach("package:lme4", unload=TRUE)
install.packages("lmerTest")
library(lmerTest)
summary(stay_fit)
summary(stay_fit)
trials_frate_scale <- trials %>% filter(!is.na(feed_rate_z)) %>% mutate(feed_rate_z=scale(feed_rate_z),chosen_out=scale(chosen_out),unchosen_out=scale(unchosen_out))
stay_fit <- lmer(stay ~ feed_rate_z + chosen_out + unchosen_out + (feed_rate_z + chosen_out + unchosen_out | sub_index),trials_frate_scale)
summary(stay_fit)
cofint(stay_fit)
confint(stay_fit)
confint(stay_fit, which="fixed")
summary(stay_fit)
confint(stay_fit, parm = c("feed_rate_z"))
summary(stay_fit)
confint(stay_fit, parm = c("feed_rate_z","chosen_out"))
summary(stay_fit)
confint(stay_fit, parm = c("feed_rate_z","chosen_out"))
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
path_to_project_directory <- "~/projects/ARL_bv/"
path_to_arl <- "~/projects/ARL/"
path_to_s22 <- "~/projects/spring_2022_study/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/final_samp_mods/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/final_samp_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_arl,"code/functions/arl_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/arlbv_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
library(tidyverse)
library(cmdstanr)
library(loo)
library(bayesplot)
library(tidybayes)
library(lmerTest)
library(sigmoid)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 5 |
valrat_skipped_percent > .1 |
late_percent > .2 |
consecutive_late_choices > 9 |
trials_completed < 144 |
sd_valrat < .05 |
percent_left > .8 |
percent_left < .2 |
percent_left_b1 < .1 |
percent_left_b1 > .9 |
percent_left_b2 < .1 |
percent_left_b2 > .9 |
percent_left_b3 < .1 |
percent_left_b3 > .9 |
answers_incorrect > 2)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 5,subs$valrat_skipped_percent[i] > .05, subs$late_percent[i] > .15,
subs$sd_valrat[i] < .1, subs$percent_left[i] > .75, subs$percent_left[i] < .25,
subs$percent_left_b1[i] > .85, subs$percent_left_b1[i] < .15, subs$percent_left_b2[i] > .85,
subs$percent_left_b2[i] < .15,subs$percent_left_b3[i] > .85, subs$percent_left_b3[i] < .15,subs$answers_incorrect[i] > 1)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late")
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
trials <- add_probe_number(trials,newcol="rat_number",val_col="valrat_z") #add rating number
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
#Create indices from 1:n_f for each fractal image. To do this, first create a mini-df with one column having all the fA_img values and the other two
#columns having indices for fA and fB. This assumes that every fA_img is paired with a unique fB_img.
f_index_df <- data.frame(fA_img = unique(trials$fA_img),fA_ix = 1:length(unique(trials$fA_img)),fB_ix = (1:length(unique(trials$fA_img))+length(unique(trials$fA_img))))
trials <- left_join(trials,f_index_df,by="fA_img")
#get the chosen fractal index
trials <- trials %>% mutate(chosen_frac = ifelse(choice == "fA",fA_ix,fB_ix))
trials <- trials %>% mutate(unchosen_frac = ifelse(choice == "fA",fB_ix,fA_ix))
fina_ls_test <- read_fsml("final_ls_test",model_out_dir=model_out_dir)
fina_ls_test$loo
flt <- read_fsml("final_ls_test",model_out_dir=model_out_dir)
flt$runtime
772.5/60
fsml_compare(rew_bv,rew_bv_pe)
view(filt_sum(rew_bv$sum,"mu"))
view(filt_sum(rew_bv_pe$sum,"mu"))
two_q_pe <- read_fsml("two_q_pe",model_out_dir=model_out_dir)
two_q <- read_fsml("two_q",model_out_dir=model_out_dir)
fsml_compare(two_q_pe,two_q)
two_q$loo
two_q_pe$loo
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
two_q <- get_loo_from_csvs(files=c("/Users/dp/projects/ARL_bv/output/results/stan_model_fits/final_samp_fits/two_q/two_q-202406271907-2-82bfa0.csv", "/Users/dp/projects/ARL_bv/output/results/stan_model_fits/final_samp_fits/two_q/two_q-202406271907-3-82bfa0.csv", "/Users/dp/projects/ARL_bv/output/results/stan_model_fits/final_samp_fits/two_q/two_q-202406271907-4-82bfa0.csv"),variables=c("choice_lik","affect_lik"))
sd(c(.05,0,-.05))
.05*38
sd(c(2,-2))
2.828427*.12
loo_compare(two_q,two_q_pe$loo)
two_q
two_q_pe$loo
two_q <- get_loo_from_csvs(files=c("/Users/dp/projects/ARL_bv/output/results/stan_model_fits/final_samp_fits/two_q/two_q-202406271907-2-82bfa0.csv", "/Users/dp/projects/ARL_bv/output/results/stan_model_fits/final_samp_fits/two_q/two_q-202406271907-3-82bfa0.csv", "/Users/dp/projects/ARL_bv/output/results/stan_model_fits/final_samp_fits/two_q/two_q-202406271907-1-82bfa0.csv"),variables=c("choice_lik","affect_lik"))
loo_compare(two_q,two_q_pe$loo)
two_q_pe_comp <- read_fsml("two_q_pe_comp",model_out_dir=model_out_dir)
loo_compare(two_q_pe_comp$loo,two_q)
two_q <- read_fsml("two_q",model_out_dir=model_out_dir)
fsml_compare(two_q,two_q_pe_comp)
fsml_compare(two_q,two_q_pe)
remove(two_q)
remove(fina_ls_test)
remove(flt)
remove(rew_bv)
remove(rew_bv_pe)
remove(two_q_pe)
remove(two_q_pe_comp)
flt <- read_fsml("final_ls_test",model_out_dir=model_out_dir)
flt_pe$loo
flt$loo
flt_pe$diagnostics
fsml_compare(flt_pe,flt)
flt_pe$loo
remove(fina_ls_test)
remov(flt)
remove(flt)
remove(flt_pe)
fsml_compare(two_q_sidebias_pe,two_q_sidebias)
two_q_sidebias <- read_fsml("two_q_sidebias",model_out_dir = model_out_dir)
fsml_compare(two_q_sidebias_pe,two_q_sidebias)
fsml_compare(mod_aff,mod_aff_pe)
mod_aff$loo
mod_aff_pe$loo
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=6)
##SET MANUALLY
path_to_project_directory <- "~/projects/spring_2022_study/"
path_to_fu_project_directory <- "~/projects/s22_follow_up/"
##############
stan_model_dir <- paste0(path_to_project_directory,"code/stan_models/final_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/final_models/")
model_out_dir_fu <- paste0(path_to_fu_project_directory,"output/results/stan_model_fits/")
library(cmdstanr)
library(tidyverse)
library(bayesplot)
library(tidybayes)
library(grid)
library(abind)
library(patchwork)
library(sigmoid)
source(paste0(path_to_project_directory,"code/functions/s22_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/stan_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/fit_stan_model.R"))
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2022-05-22_19_14_57.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2022-05-22_19_14_57.csv"))
?add_lag_cols()
trials_fres_lags <- add_lag_cols(trials_fres,valrat_z,out,lags=c(1:4))
trials_diffs <- do.call(rbind,by(trials,trials$sub_index,sub_past_diffs))
trials_diffs <- do.call(rbind,by(trials,trials$sub_index,sub_past_diffs))
source("~/projects/ARL_bv/code/functions/arlbv_utilities.R", echo=TRUE)
trials_diffs <- do.call(rbind,by(trials,trials$sub_index,sub_past_diffs))
source("~/projects/ARL_bv/code/functions/arlbv_utilities.R", echo=TRUE)
trials_diffs <- do.call(rbind,by(trials,trials$sub_index,sub_past_diffs))
nrow(trials$sub_index)
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
path_to_project_directory <- "~/projects/ARL_bv/"
path_to_arl <- "~/projects/ARL/"
path_to_s22 <- "~/projects/spring_2022_study/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/final_samp_mods/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/final_samp_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_arl,"code/functions/arl_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/arlbv_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
library(tidyverse)
library(cmdstanr)
library(loo)
library(bayesplot)
library(tidybayes)
library(lmerTest)
library(sigmoid)
source("~/projects/ARL_bv/code/functions/arlbv_utilities.R", echo=TRUE)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 5 |
valrat_skipped_percent > .1 |
late_percent > .2 |
consecutive_late_choices > 9 |
trials_completed < 144 |
sd_valrat < .05 |
percent_left > .8 |
percent_left < .2 |
percent_left_b1 < .1 |
percent_left_b1 > .9 |
percent_left_b2 < .1 |
percent_left_b2 > .9 |
percent_left_b3 < .1 |
percent_left_b3 > .9 |
answers_incorrect > 2)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 5,subs$valrat_skipped_percent[i] > .05, subs$late_percent[i] > .15,
subs$sd_valrat[i] < .1, subs$percent_left[i] > .75, subs$percent_left[i] < .25,
subs$percent_left_b1[i] > .85, subs$percent_left_b1[i] < .15, subs$percent_left_b2[i] > .85,
subs$percent_left_b2[i] < .15,subs$percent_left_b3[i] > .85, subs$percent_left_b3[i] < .15,subs$answers_incorrect[i] > 1)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late")
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
trials <- add_probe_number(trials,newcol="rat_number",val_col="valrat_z") #add rating number
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
#Create indices from 1:n_f for each fractal image. To do this, first create a mini-df with one column having all the fA_img values and the other two
#columns having indices for fA and fB. This assumes that every fA_img is paired with a unique fB_img.
f_index_df <- data.frame(fA_img = unique(trials$fA_img),fA_ix = 1:length(unique(trials$fA_img)),fB_ix = (1:length(unique(trials$fA_img))+length(unique(trials$fA_img))))
trials <- left_join(trials,f_index_df,by="fA_img")
#get the chosen fractal index
trials <- trials %>% mutate(chosen_frac = ifelse(choice == "fA",fA_ix,fB_ix))
trials <- trials %>% mutate(unchosen_frac = ifelse(choice == "fA",fB_ix,fA_ix))
trials_diffs <- do.call(rbind,by(trials,trials$sub_index,sub_past_diffs))
diff_reg_fit_3 <- lm(stay ~ valrat_z_diff_1 + out_diff_1 + valrat_z_diff_2 + out_diff_2 + valrat_z_diff_3 + out_diff_3,trials_diffs)
summary(diff_reg_fit_3)
summary(diff_reg_fit_3)$coefficients
library(Car)
library(car)
linearHypothesis(diff_reg_fit_3,"valrat_z_diff_1 - valrat_z_diff_2 = 0")
summary(linearHypothesis(diff_reg_fit_3,"valrat_z_diff_1 - valrat_z_diff_2 = 0"))
linearHypothesis(diff_reg_fit_3,"valrat_z_diff_1 - valrat_z_diff_2 = 0")
linearHypothesis(diff_reg_fit_3,"valrat_z_diff_2 - valrat_z_diff_3 = 0")
linearHypothesis(diff_reg_fit_3,"valrat_z_diff_1 - valrat_z_diff_3 = 0")
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
path_to_project_directory <- "~/projects/ARL_bv/"
path_to_arl <- "~/projects/ARL/"
path_to_s22 <- "~/projects/spring_2022_study/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/final_samp_mods/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/final_samp_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_arl,"code/functions/arl_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/arlbv_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
library(tidyverse)
library(cmdstanr)
library(loo)
library(bayesplot)
library(tidybayes)
library(lmerTest)
library(sigmoid)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 5 |
valrat_skipped_percent > .1 |
late_percent > .2 |
consecutive_late_choices > 9 |
trials_completed < 144 |
sd_valrat < .05 |
percent_left > .8 |
percent_left < .2 |
percent_left_b1 < .1 |
percent_left_b1 > .9 |
percent_left_b2 < .1 |
percent_left_b2 > .9 |
percent_left_b3 < .1 |
percent_left_b3 > .9 |
answers_incorrect > 2)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 5,subs$valrat_skipped_percent[i] > .05, subs$late_percent[i] > .15,
subs$sd_valrat[i] < .1, subs$percent_left[i] > .75, subs$percent_left[i] < .25,
subs$percent_left_b1[i] > .85, subs$percent_left_b1[i] < .15, subs$percent_left_b2[i] > .85,
subs$percent_left_b2[i] < .15,subs$percent_left_b3[i] > .85, subs$percent_left_b3[i] < .15,subs$answers_incorrect[i] > 1)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late")
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
trials <- add_probe_number(trials,newcol="rat_number",val_col="valrat_z") #add rating number
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
#Create indices from 1:n_f for each fractal image. To do this, first create a mini-df with one column having all the fA_img values and the other two
#columns having indices for fA and fB. This assumes that every fA_img is paired with a unique fB_img.
f_index_df <- data.frame(fA_img = unique(trials$fA_img),fA_ix = 1:length(unique(trials$fA_img)),fB_ix = (1:length(unique(trials$fA_img))+length(unique(trials$fA_img))))
trials <- left_join(trials,f_index_df,by="fA_img")
#get the chosen fractal index
trials <- trials %>% mutate(chosen_frac = ifelse(choice == "fA",fA_ix,fB_ix))
trials <- trials %>% mutate(unchosen_frac = ifelse(choice == "fA",fB_ix,fA_ix))
rew_bv <- read_fsml("rew_bv",model_out_dir=model_out_dir)
rew_bv$runtime
fsml_compare(rew_min_bv,rew_min_bv_pe)
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
path_to_project_directory <- "~/projects/ARL_bv/"
path_to_arl <- "~/projects/ARL/"
path_to_s22 <- "~/projects/spring_2022_study/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/final_samp_mods/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/final_samp_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_arl,"code/functions/arl_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/arlbv_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
library(tidyverse)
library(cmdstanr)
library(loo)
library(bayesplot)
library(tidybayes)
library(lmerTest)
library(sigmoid)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 5 |
valrat_skipped_percent > .1 |
late_percent > .2 |
consecutive_late_choices > 9 |
trials_completed < 144 |
sd_valrat < .05 |
percent_left > .8 |
percent_left < .2 |
percent_left_b1 < .1 |
percent_left_b1 > .9 |
percent_left_b2 < .1 |
percent_left_b2 > .9 |
percent_left_b3 < .1 |
percent_left_b3 > .9 |
answers_incorrect > 2)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 5,subs$valrat_skipped_percent[i] > .05, subs$late_percent[i] > .15,
subs$sd_valrat[i] < .1, subs$percent_left[i] > .75, subs$percent_left[i] < .25,
subs$percent_left_b1[i] > .85, subs$percent_left_b1[i] < .15, subs$percent_left_b2[i] > .85,
subs$percent_left_b2[i] < .15,subs$percent_left_b3[i] > .85, subs$percent_left_b3[i] < .15,subs$answers_incorrect[i] > 1)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late")
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
trials <- add_probe_number(trials,newcol="rat_number",val_col="valrat_z") #add rating number
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
#Create indices from 1:n_f for each fractal image. To do this, first create a mini-df with one column having all the fA_img values and the other two
#columns having indices for fA and fB. This assumes that every fA_img is paired with a unique fB_img.
f_index_df <- data.frame(fA_img = unique(trials$fA_img),fA_ix = 1:length(unique(trials$fA_img)),fB_ix = (1:length(unique(trials$fA_img))+length(unique(trials$fA_img))))
trials <- left_join(trials,f_index_df,by="fA_img")
#get the chosen fractal index
trials <- trials %>% mutate(chosen_frac = ifelse(choice == "fA",fA_ix,fB_ix))
trials <- trials %>% mutate(unchosen_frac = ifelse(choice == "fA",fB_ix,fA_ix))
two_q_sidebias <- read_fsml("two_q_sidebias",model_out_dir=model_out_dir)
two_q_sidebias_pe <- read_fsml("two_q_sidebias_pe",model_out_dir=model_out_dir)
fsml_compare(two_q_sidebias_pe,two_q_sidebias)
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
##SET MANUALLY
path_to_project_directory <- "~/projects/s22_follow_up/"
path_to_s22 <- "~/projects/spring_2022_study/"
##############
stan_model_dir_s22fu <- paste0(path_to_project_directory,"code/stan_models/")
stan_model_dir_s22 <- paste0(path_to_s22,"code/stan_models/final_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/")
library(cmdstanr)
library(tidyverse)
library(tidybayes)
library(loo)
library(GGally)
library(bayesplot)
library(sigmoid)
library(abind)
library(lmerTest)
source(paste0(path_to_project_directory,"code/functions/s22fu_utilities.R"))
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2023-06-12_09_56_03.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2023-06-12_09_56_03.csv"))
#identify subjects who fail the hard QC cutoffs
sub_hard_fail <- subs %>% filter(att_checks_passed < 3 |
percent_left > .8 |
percent_left < .2 |
consecutive_late_choices > 5 |
late_percent > .2 |
answers_incorrect > 2 |
trials_completed < 104 |
valrate_skipped_percent > .14 |
valence_sd < .1 |
decrate_sd < .05 |
feedrate_sd < .05)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$consecutive_auto_process[i] > 4,subs$att_checks_passed[i] < 4,subs$answers_incorrect[i] > 1,
subs$late_percent[i] > .1,subs$valrate_skipped_percent[i] > .07,
subs$choice_pt_completed[i] == 0, subs$decrate_pt_completed[i] == 0, subs$feedrate_pt_completed == 0)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #mark subjects who fail on either hard or soft or criteria for exclusion
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late") #filter out bad subjects, as well as trials on which the subject failed to make a choice
subs <- subs %>% filter(!(id %in% subs_to_exclude))
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
#get mean-centered trial and block predictors for easier fitting in Stan
trials$trial_nl_cent <- trials$trial_nl - mean(trials$trial_nl)
trials$block_cent <- trials$block - mean(trials$block)
#Create indices from 1:n_f for each fractal image. To do this, first create a mini-df with one column having all the fA_img values and the other two
#columns having indices for fA and fB. This assumes that every fA_img is paired with a unique fB_img.
f_index_df <- data.frame(fA_img = unique(trials$fA_img),fA_ix = 1:length(unique(trials$fA_img)),fB_ix = (1:length(unique(trials$fA_img))+length(unique(trials$fA_img))))
trials <- left_join(trials,f_index_df,by="fA_img")
#get the chosen fractal index
trials <- trials %>% mutate(chosen_frac = ifelse(choice == "fA",fA_ix,fB_ix))
trials <- trials %>% mutate(unchosen_frac = ifelse(choice == "fA",fB_ix,fA_ix))
#add a column with the affect probe number for each subject (999 if no probe response). These will be passed into Stan
trials <- add_probe_number(trials,newcol="dec_probe_number",val_col="dec_rate") #for decision probes
trials <- add_probe_number(trials,newcol="feed_probe_number",val_col="feed_rate") #for decision probes
ratings_arl <- read_fsml("ratings_arl",model_out_dir=model_out_dir)
ratings_arl_pe <- read_fsml("ratings_arl_pe",model_out_dir=model_out_dir)
fsml_compare(ratings_arl_pe,ratings_arl)
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
##SET MANUALLY
path_to_project_directory <- "~/projects/spring_2022_study/"
path_to_fu_project_directory <- "~/projects/s22_follow_up/"
##############
stan_model_dir <- paste0(path_to_project_directory,"code/stan_models/final_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/final_models/")
model_out_dir_fu <- paste0(path_to_fu_project_directory,"output/results/stan_model_fits/")
library(cmdstanr)
library(tidyverse)
library(bayesplot)
library(tidybayes)
library(grid)
library(abind)
library(patchwork)
library(sigmoid)
source(paste0(path_to_project_directory,"code/functions/s22_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/stan_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/fit_stan_model.R"))
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2022-05-22_19_14_57.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2022-05-22_19_14_57.csv"))
#identify subjects who fail the hard QC cutoffs
sub_hard_fail <- subs %>% filter(att_checks_passed == 0 |
percent_left > .8 |
percent_left < .2 |
consecutive_late_choices > 5 |
late_percent > .2 |
answers_incorrect > 2 |
trials_completed < 126 |
probe_skipped_percent > .14 |
id %in% c(86956,86746,86839,80227,79198,86503,86869,85588))
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$consecutive_auto_process[i] > 4,subs$att_checks_passed[i] == 1,subs$answers_incorrect[i] > 1,
subs$late_percent[i] > .1,subs$probe_skipped_percent[i] > .07,subs$noprobe_pt_choices[i] == 0,subs$probe_pt_choices[i] == 0)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #mark subjects who fail on either hard or soft or criteria for exclusion
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late") #filter out bad subjects, as well as trials on which the subject failed to make a choice
subs <- subs %>% filter(!(id %in% subs_to_exclude))
#trials <- trials %>% filter(!(id %in% c(86077,86134,86356,87163,86458,85588,86869,86956,86746,79198,86359,86503,86881))) %>% filter(choice != "late")
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
#convert affect ratings to subject-by-subject z-scores, to control for intersubject differences in rating variability
trials[c("valence_dec","valence_feed")] <- trials[c("valence_dec","valence_feed")]*-1 #flip the affect ratings, so that the low numbers
#correspond to low values of valence
trials <- do.call(rbind,by(trials,trials$id,col_zscore,c("valence_dec","valence_feed"))) #translate valence ratings to z-scores
#add a column with the affect probe number for each subject (999 if no probe response). These will be passed into Stan
trials <- add_probe_number(trials,newcol="dec_probe_number",val_col="valence_dec",arous_col="arousal_dec") #for decision probes
trials <- add_probe_number(trials,newcol="feed_probe_number",val_col="valence_feed",arous_col="arousal_feed") #for feedback probes
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
trials <- trials %>% mutate(dec_probe_completed = if_else(is.na(arousal_dec) | is.na(valence_dec),0,1)) #add a 1/0 column indicating whether a
#decision probe was completed on each trial
trials <- trials %>% mutate(feed_probe_completed = if_else(is.na(arousal_feed) | is.na(valence_feed),0,1)) #diddo feedback
#get mean-centeedr trial and block predictors for easier fitting in Stan
trials$trial_nl_cent <- trials$trial_nl - mean(trials$trial_nl)
trials$block_cent <- trials$block - mean(trials$block)
#get the chosen fractal index
trials <- trials %>% mutate(chosen_frac = ifelse(choice == "fractal_a_dec",fractal_a_num,fractal_b_num))
trials <- trials %>% mutate(unchosen_frac = ifelse(choice == "fractal_a_dec",fractal_b_num,fractal_a_num))
#add columns showing the pairs at play in each block
new_trials_list <- by(trials,trials$id,create_pair_cols_sub)
trials <- do.call(rbind,new_trials_list)
arl <- read_fsml("arl",model_out_dir=model_out_dir)
arl_pe <- read_fsml("arl_pe",model_out_dir=model_out_dir)
fsml_compare(arl_pe,arl)
