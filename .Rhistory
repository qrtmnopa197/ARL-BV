subs$percent_left_b1[i] > .83, subs$percent_left_b1[i] < .17, subs$percent_left_b2[i] > .83,
subs$percent_left_b2[i] < .17,subs$percent_left_b3[i] > .83, subs$percent_left_b3[i] < .17,subs$answers_incorrect[i] > 1)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #mark subjects who fail on either hard or soft or criteria for exclusion
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late")
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/length(subs)
length(subs_to_exclude)
length(subs)
nrow(subs)
36/95
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=6)
path_to_project_directory <- "~/projects/ARL_bv/"
path_to_arl <- "~/projects/ARL/"
path_to_s22 <- "~/projects/spring_2022_study/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/final_samp_mods/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/final_samp_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_arl,"code/functions/arl_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/arlbv_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
library(tidyverse)
library(cmdstanr)
library(loo)
library(bayesplot)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
two_q <- read_fsml("two_q",model_out_dir=model_out_dir)
filt_sum(two_q$sum,"sens_mu")
2/3
.67*05
.67*.05
.0335*29
sigmoid(1)
library(sigmoid(1))
library(sigmoid
)
library(sigmoid)
sigmoid(1)
sigmoid(.62)
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=6)
path_to_project_directory <- "~/projects/ARL_bv/"
path_to_arl <- "~/projects/ARL/"
path_to_s22 <- "~/projects/spring_2022_study/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/final_samp_mods/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/final_samp_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_arl,"code/functions/arl_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/arlbv_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
library(tidyverse)
library(cmdstanr)
library(loo)
library(bayesplot)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 5 |
valrat_skipped_percent > .1 |
late_percent > .2 |
consecutive_late_choices > 9 |
trials_completed < 144 |
sd_valrat < .05 |
percent_left > .8 |
percent_left < .2 |
percent_left_b1 < .1 |
percent_left_b1 > .9 |
percent_left_b2 < .1 |
percent_left_b2 > .9 |
percent_left_b3 < .1 |
percent_left_b3 > .9 |
answers_incorrect > 2)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 5,subs$valrat_skipped_percent[i] > .05, subs$late_percent[i] > .15,
subs$sd_valrat[i] < .1, subs$percent_left[i] > .75, subs$percent_left[i] < .25,
subs$percent_left_b1[i] > .85, subs$percent_left_b1[i] < .15, subs$percent_left_b2[i] > .85,
subs$percent_left_b2[i] < .15,subs$percent_left_b3[i] > .85, subs$percent_left_b3[i] < .15,subs$answers_incorrect[i] > 1)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late")
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
trials <- add_probe_number(trials,newcol="rat_number",val_col="valrat_z") #add rating number
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=6)
path_to_project_directory <- "~/projects/ARL_bv/"
path_to_arl <- "~/projects/ARL/"
path_to_s22 <- "~/projects/spring_2022_study/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/final_samp_mods/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/final_samp_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_arl,"code/functions/arl_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/arlbv_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
library(tidyverse)
library(cmdstanr)
library(loo)
library(bayesplot)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 5 |
valrat_skipped_percent > .1 |
late_percent > .2 |
consecutive_late_choices > 9 |
trials_completed < 144 |
sd_valrat < .05 |
percent_left > .8 |
percent_left < .2 |
percent_left_b1 < .1 |
percent_left_b1 > .9 |
percent_left_b2 < .1 |
percent_left_b2 > .9 |
percent_left_b3 < .1 |
percent_left_b3 > .9 |
answers_incorrect > 2)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 5,subs$valrat_skipped_percent[i] > .05, subs$late_percent[i] > .15,
subs$sd_valrat[i] < .1, subs$percent_left[i] > .75, subs$percent_left[i] < .25,
subs$percent_left_b1[i] > .85, subs$percent_left_b1[i] < .15, subs$percent_left_b2[i] > .85,
subs$percent_left_b2[i] < .15,subs$percent_left_b3[i] > .85, subs$percent_left_b3[i] < .15,subs$answers_incorrect[i] > 1)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late")
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
trials <- add_probe_number(trials,newcol="rat_number",val_col="valrat_z") #add rating number
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
two_q <- read_fsml("two_q",model_out_dir=model_out_dir)
view(two_q$sum)
two_q <- ""
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
path_to_project_directory <- "~/projects/ARL_bv/"
path_to_arl <- "~/projects/ARL/"
path_to_s22 <- "~/projects/spring_2022_study/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/final_samp_mods/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/final_samp_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_arl,"code/functions/arl_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/arlbv_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
library(tidyverse)
library(cmdstanr)
library(loo)
library(bayesplot)
library(tidybayes)
library(lme4)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 5 |
valrat_skipped_percent > .1 |
late_percent > .2 |
consecutive_late_choices > 9 |
trials_completed < 144 |
sd_valrat < .05 |
percent_left > .8 |
percent_left < .2 |
percent_left_b1 < .1 |
percent_left_b1 > .9 |
percent_left_b2 < .1 |
percent_left_b2 > .9 |
percent_left_b3 < .1 |
percent_left_b3 > .9 |
answers_incorrect > 2)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 5,subs$valrat_skipped_percent[i] > .05, subs$late_percent[i] > .15,
subs$sd_valrat[i] < .1, subs$percent_left[i] > .75, subs$percent_left[i] < .25,
subs$percent_left_b1[i] > .85, subs$percent_left_b1[i] < .15, subs$percent_left_b2[i] > .85,
subs$percent_left_b2[i] < .15,subs$percent_left_b3[i] > .85, subs$percent_left_b3[i] < .15,subs$answers_incorrect[i] > 1)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late")
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
trials <- add_probe_number(trials,newcol="rat_number",val_col="valrat_z") #add rating number
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
#Create indices from 1:n_f for each fractal image. To do this, first create a mini-df with one column having all the fA_img values and the other two
#columns having indices for fA and fB. This assumes that every fA_img is paired with a unique fB_img.
f_index_df <- data.frame(fA_img = unique(trials$fA_img),fA_ix = 1:length(unique(trials$fA_img)),fB_ix = (1:length(unique(trials$fA_img))+length(unique(trials$fA_img))))
trials <- left_join(trials,f_index_df,by="fA_img")
#get the chosen fractal index
trials <- trials %>% mutate(chosen_frac = ifelse(choice == "fA",fA_ix,fB_ix))
trials <- trials %>% mutate(unchosen_frac = ifelse(choice == "fA",fB_ix,fA_ix))
temp_breakdown <- read_fsml("temp_breakdown",model_out_dir=model_out_dir)
fsml_compare(temp_breakdown,breakdown)
scd_ma <- get_draws("breakdown",model_out_dir,vars=c("scd_ma_fr_sens_mu"))
quantile(scd_ma,c(0.5,.5,.95))
quantile(scd_ma,c(0.05,.5,.95))
scd_rew <- get_draws("breakdown",model_out_dir,vars=c("scd_rew_fr_sens_mu"))
mean(scd_ma > scd_rew)
quantile(scd_rew,c(0.05,.5,.95))
scd_resid <- get_draws("breakdown",model_out_dir,vars=c("scd_resid_fr_sens_mu"))
quantile(scd_ma,c(0.05,.5,.95))
quantile(scd_resid,c(0.05,.5,.95))
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
path_to_project_directory <- "~/projects/ARL_bv/"
path_to_arl <- "~/projects/ARL/"
path_to_s22 <- "~/projects/spring_2022_study/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/final_samp_mods/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/final_samp_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_arl,"code/functions/arl_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/arlbv_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
library(tidyverse)
library(cmdstanr)
library(loo)
library(bayesplot)
library(tidybayes)
library(lme4)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 5 |
valrat_skipped_percent > .1 |
late_percent > .2 |
consecutive_late_choices > 9 |
trials_completed < 144 |
sd_valrat < .05 |
percent_left > .8 |
percent_left < .2 |
percent_left_b1 < .1 |
percent_left_b1 > .9 |
percent_left_b2 < .1 |
percent_left_b2 > .9 |
percent_left_b3 < .1 |
percent_left_b3 > .9 |
answers_incorrect > 2)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 5,subs$valrat_skipped_percent[i] > .05, subs$late_percent[i] > .15,
subs$sd_valrat[i] < .1, subs$percent_left[i] > .75, subs$percent_left[i] < .25,
subs$percent_left_b1[i] > .85, subs$percent_left_b1[i] < .15, subs$percent_left_b2[i] > .85,
subs$percent_left_b2[i] < .15,subs$percent_left_b3[i] > .85, subs$percent_left_b3[i] < .15,subs$answers_incorrect[i] > 1)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late")
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
trials <- add_probe_number(trials,newcol="rat_number",val_col="valrat_z") #add rating number
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
#Create indices from 1:n_f for each fractal image. To do this, first create a mini-df with one column having all the fA_img values and the other two
#columns having indices for fA and fB. This assumes that every fA_img is paired with a unique fB_img.
f_index_df <- data.frame(fA_img = unique(trials$fA_img),fA_ix = 1:length(unique(trials$fA_img)),fB_ix = (1:length(unique(trials$fA_img))+length(unique(trials$fA_img))))
trials <- left_join(trials,f_index_df,by="fA_img")
#get the chosen fractal index
trials <- trials %>% mutate(chosen_frac = ifelse(choice == "fA",fA_ix,fB_ix))
trials <- trials %>% mutate(unchosen_frac = ifelse(choice == "fA",fB_ix,fA_ix))
sfres <- trials %>% filter(show_fres == 1)
lm(valrat_z ~ out,sfres)
summary(lm(valrat_z ~ out,sfres))
nfres <- trials %>% filter(show_fres == 0)
summary(lm(valrat_z ~ out,nfres))
11.3/.52
#This is the master script for initial data analysis steps
#It identifies data to use, wrangles it into a usable form, creates additional variables based on this data, and creates plots of certain variables for quality-checking.
##SET MANUALLY
path_to_project_directory <- "~/projects/RVA/"
path_to_s22 <- "~/projects/spring_2022_study/"
path_to_s22fu <- "~/projects/s22_follow_up/"
ids_to_exclude <- c(86041,1,93151) #Ps whose data you don't want to analyze even if it looks good
##############
#clear out results from old analyses
system("mv /Users/dp/projects/RVA/analysis_data/*.csv /Users/dp/projects/RVA/analysis_data/old_analysis_data") #move any CSV files in this folder to old_analysis_data folder
system("rm -rf /Users/dp/projects/RVA/analysis_data/qc_plots/trial_level_vars/*") #clear the folder containing trial-level plots
system("rm -f /Users/dp/projects/RVA/analysis_data/qc_plots/sub_level_variables.pdf") #remove old subject level variable plot
#read in necessary functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22fu,"code/functions/s22fu_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/rva_wrangle_psychopy_data.R"))
csvs_to_analyze <- get_csvs_to_analyze(path_to_project_directory,ids_to_exclude) #get the usable CSVs to analyze
all_data <- lapply(csvs_to_analyze, rva_wrangle_psychopy_data) #reformats each CSV, turning it into a long dataset usable for analysis, and adds all variables of interest that can be created from the raw data alone.
#Returns a list - one element for each subject - where each element is itself a list containing dfs with the trial-level data and subject-level data
trials_list <- lapply(all_data, function(l) l[[1]]) #get a list of the trial-level dfs only
trial_level_data <- do.call(rbind,trials_list) #stack trial dfs into one big df
sub_list <- lapply(all_data, function(l) l[[2]]) #get a list of the subject-level dfs only
sub_level_data <- do.call(rbind,sub_list) #stack them into one big data frame
#write both to CSVs
date_time <- Sys.time() %>% chartr(" ","_",.) %>% chartr(":","_",.) #grab the date and time, reformatting ':' and '-' to  '_' so you can label the files with it
write.csv(trial_level_data,paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_",date_time,".csv"),row.names = FALSE)
#write subject-level data
write.csv(sub_level_data,paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_",date_time,".csv"),row.names = FALSE)
#Create plot grids of select variables for quality checking. These are saved to the qc_plots folder
tl_hists <- c("val_rat_rt","prob_rat_rt","val_rat","prob_rat") #trial level variables to plot
plot_trial_level_vars(trial_level_data,tl_hists,path_to_project_directory) #create and save plot grids
sl_hists <- c("answers_incorrect","instruct_keypress",
"feed_check_passed","aff_check_passed","worth_check_passed","att_checks_passed",
"probrat_skipped_percent","sd_probrat","mean_probrat_rt",
"valrat_skipped_percent","sd_valrat","mean_valrat_rt",
"earnings","total_experiment_time") #subject-level variables to plot
plot_sub_level_vars(sub_level_data,sl_hists,path_to_project_directory) #create and save plot grids
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
path_to_project_directory <- "~/projects/ARL_bv/"
path_to_arl <- "~/projects/ARL/"
path_to_s22 <- "~/projects/spring_2022_study/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/final_samp_mods/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/final_samp_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_arl,"code/functions/arl_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/arlbv_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
library(tidyverse)
library(cmdstanr)
library(loo)
library(bayesplot)
library(tidybayes)
library(lme4)
breakdown <- read_fsml("breakdown",model_out_dir=model_out_dir)
view(filt_sum(breakdown$sum,"mu"))
view(filt_sum(breakdown$sum,"scd"))
view(filt_sum(breakdown$sum,"scd_ma_fres_sens_mu"))
view(breakdown$sum)
breakdown_ma_sens <- get_draws("breakdown",vars=c("scd_ma_fr_sens_mu"))
median(breakdown_ma_sens)
mod_aff_ma_sens <- get_draws("mod_aff_resid",vars=c("scd_ma_fr_sens_mu"))
dim(breakdown_ma_sens)
quantile(breakdown_ma_sens,probs=c(.025,.05,.5,.95,.975))
breakdown_rew_sens <- get_draws("breakdown",vars=c("scd_rew_fr_sens_mu"))
quantile(breakdown_rew_sens,probs=c(.025,.5,.975))
quantile(breakdown_ma_sens - breakdown_rew_sens,probs=c(.025,.5,.975))
quantile(breakdown_rew_sens,probs=c(.025,.5,.975))
breakdown_resid_sens <- get_draws("breakdown",vars=c("scd_resid_fr_sens_mu"))
quantile(breakdown_resid_sens,probs=c(.025,.5,.975))
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
path_to_project_directory <- "~/projects/ARL_bv/"
path_to_arl <- "~/projects/ARL/"
path_to_s22 <- "~/projects/spring_2022_study/"
stan_model_dir<- paste0(path_to_project_directory,"code/stan_models/final_samp_mods/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/final_samp_fits/")
#load custom functions
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_arl,"code/functions/arl_utilities.R"))
source(paste0(path_to_project_directory,"code/functions/arlbv_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
library(tidyverse)
library(cmdstanr)
library(loo)
library(bayesplot)
library(tidybayes)
library(lme4)
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2023-11-27_18_52_39.243708.csv"))
sub_hard_fail <- subs %>% filter(att_checks_passed < 5 |
valrat_skipped_percent > .1 |
late_percent > .2 |
consecutive_late_choices > 9 |
trials_completed < 144 |
sd_valrat < .05 |
percent_left > .8 |
percent_left < .2 |
percent_left_b1 < .1 |
percent_left_b1 > .9 |
percent_left_b2 < .1 |
percent_left_b2 > .9 |
percent_left_b3 < .1 |
percent_left_b3 > .9 |
answers_incorrect > 2)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$att_checks_passed[i] == 5,subs$valrat_skipped_percent[i] > .05, subs$late_percent[i] > .15,
subs$sd_valrat[i] < .1, subs$percent_left[i] > .75, subs$percent_left[i] < .25,
subs$percent_left_b1[i] > .85, subs$percent_left_b1[i] < .15, subs$percent_left_b2[i] > .85,
subs$percent_left_b2[i] < .15,subs$percent_left_b3[i] > .85, subs$percent_left_b3[i] < .15,subs$answers_incorrect[i] > 1)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #get subjects who failed either set of criteria
#clean data
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late")
subs <- subs %>% filter(!(id %in% subs_to_exclude))
length(subs_to_exclude)/(nrow(subs)+length(subs_to_exclude)) #get percent excluded
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
trials <- add_probe_number(trials,newcol="rat_number",val_col="valrat_z") #add rating number
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
#Create indices from 1:n_f for each fractal image. To do this, first create a mini-df with one column having all the fA_img values and the other two
#columns having indices for fA and fB. This assumes that every fA_img is paired with a unique fB_img.
f_index_df <- data.frame(fA_img = unique(trials$fA_img),fA_ix = 1:length(unique(trials$fA_img)),fB_ix = (1:length(unique(trials$fA_img))+length(unique(trials$fA_img))))
trials <- left_join(trials,f_index_df,by="fA_img")
#get the chosen fractal index
trials <- trials %>% mutate(chosen_frac = ifelse(choice == "fA",fA_ix,fB_ix))
trials <- trials %>% mutate(unchosen_frac = ifelse(choice == "fA",fB_ix,fA_ix))
two_q_pe <- fit_stan_model(stan_file=paste0(stan_model_dir,"two_q_pe.stan"),
model_out_dir=model_out_dir,
raw_data=trials,
study = "arlbv",
chains = 3,
n_t = 144)
knitr::opts_chunk$set(echo = TRUE)
options(mc.cores=12)
##SET MANUALLY
path_to_project_directory <- "~/projects/s22_follow_up/"
path_to_s22 <- "~/projects/spring_2022_study/"
##############
stan_model_dir_s22fu <- paste0(path_to_project_directory,"code/stan_models/")
stan_model_dir_s22 <- paste0(path_to_s22,"code/stan_models/final_models/")
model_out_dir <- paste0(path_to_project_directory,"output/results/stan_model_fits/")
library(cmdstanr)
library(tidyverse)
library(tidybayes)
library(loo)
library(GGally)
library(bayesplot)
library(sigmoid)
library(abind)
source(paste0(path_to_project_directory,"code/functions/s22fu_utilities.R"))
source(paste0(path_to_s22,"code/functions/s22_utilities.R"))
source(paste0(path_to_s22,"code/functions/stan_utilities.R"))
source(paste0(path_to_s22,"code/functions/fit_stan_model.R"))
trials <- read.csv(paste0(path_to_project_directory,"analysis_data/trial_level_data_all_subs_2023-06-12_09_56_03.csv"))
subs <- read.csv(paste0(path_to_project_directory,"analysis_data/sub_level_data_all_subs_2023-06-12_09_56_03.csv"))
#identify subjects who fail the hard QC cutoffs
sub_hard_fail <- subs %>% filter(att_checks_passed < 3 |
percent_left > .8 |
percent_left < .2 |
consecutive_late_choices > 5 |
late_percent > .2 |
answers_incorrect > 2 |
trials_completed < 104 |
valrate_skipped_percent > .14 |
valence_sd < .1 |
decrate_sd < .05 |
feedrate_sd < .05)
#count the number of soft QC cutoffs each subject meets
subs$softs <- 0
for(i in 1:nrow(subs)){
subs$softs[i] <- length(which(c(subs$consecutive_auto_process[i] > 4,subs$att_checks_passed[i] < 4,subs$answers_incorrect[i] > 1,
subs$late_percent[i] > .1,subs$valrate_skipped_percent[i] > .07,
subs$choice_pt_completed[i] == 0, subs$decrate_pt_completed[i] == 0, subs$feedrate_pt_completed == 0)))
}
sub_soft_fail <- filter(subs,softs >= 2) #identify those who meet more than 2 soft cutoffs
subs_to_exclude <- unique(c(sub_hard_fail$id,sub_soft_fail$id)) #mark subjects who fail on either hard or soft or criteria for exclusion
trials <- trials %>% filter(!(id %in% subs_to_exclude)) %>% filter(choice != "late") #filter out bad subjects, as well as trials on which the subject failed to make a choice
subs <- subs %>% filter(!(id %in% subs_to_exclude))
trials <- add_sub_indices(trials) #add subject indices to the df. These will match the indices used in Stan.
#add a column with completed trial numbers - the trial indices if you ignore late trials. These will match the "t" trial numbers used in the Stan models
trials <- do.call(rbind,by(trials,trials$sub_index,add_trials_nl))
trials$overall_trial_nl <- 1:nrow(trials) #get the overall trial number ignoring late trials and collapsing across subjects
#get mean-centered trial and block predictors for easier fitting in Stan
trials$trial_nl_cent <- trials$trial_nl - mean(trials$trial_nl)
trials$block_cent <- trials$block - mean(trials$block)
#Create indices from 1:n_f for each fractal image. To do this, first create a mini-df with one column having all the fA_img values and the other two
#columns having indices for fA and fB. This assumes that every fA_img is paired with a unique fB_img.
f_index_df <- data.frame(fA_img = unique(trials$fA_img),fA_ix = 1:length(unique(trials$fA_img)),fB_ix = (1:length(unique(trials$fA_img))+length(unique(trials$fA_img))))
trials <- left_join(trials,f_index_df,by="fA_img")
#get the chosen fractal index
trials <- trials %>% mutate(chosen_frac = ifelse(choice == "fA",fA_ix,fB_ix))
trials <- trials %>% mutate(unchosen_frac = ifelse(choice == "fA",fB_ix,fA_ix))
#add a column with the affect probe number for each subject (999 if no probe response). These will be passed into Stan
trials <- add_probe_number(trials,newcol="dec_probe_number",val_col="dec_rate") #for decision probes
trials <- add_probe_number(trials,newcol="feed_probe_number",val_col="feed_rate") #for decision probes
model_pred_arl_nonuis_pe <- fit_stan_model(stan_file = paste0(stan_model_dir_s22fu,"model_pred_arl_nonuis_pe.stan"),
model_out_dir = model_out_dir,
raw_data = trials,
study = "s22fu",
iter_sampling = 1500,
n_t=104)
model_pred_arl_nonuis <- read_fsml("model_pred_arl_nonuis")
model_pred_arl_nonuis <- read_fsml("model_pred_arl_nonuis",model_out_dir="/Users/dp/projects/spring_2022_study/output/results/stan_model_fits")
model_pred_arl_nonuis <- read_fsml("model_pred_arl_nonuis",model_out_dir="/Users/dp/projects/spring_2022_study/output/results/stan_model_fits/")
model_pred_arl_nonuis <- read_fsml("model_pred_arl_nonuis",model_out_dir="/Users/dp/projects/s22_follow_up/output/results/stan_model_fits/")
fsml_compare(model_pred_arl_nonuis,model_pred_arl_nonuis_pe)
model_pred_arl_nonuis$diagnostics
model_pred_arl_nonuis_pe$diagnostics
model_pred_arl_nonuis_pe$loo
model_pred_arl_nonuis$loo
